{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/benza613/Sentiment-Analysis-using-Deep-Learning/blob/master/notebooks/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciJxdHqb_RL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QSZkFOkPb5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd gdrive/My\\ Drive/SNLP"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg_Q8_6Y_hYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "%cd /content/drive/My\\ Drive/SNLP\\ Project\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNFlsOhiATny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load your choice of dataset here . Specify paths as folder_datestring/file_datestring.zip\n",
        "\n",
        "Train_ZipCSVFileName = 'amz_all_electronics/Data_Balanced_2000_Apr-03-2020_06-46/Train_2000_Apr-03-2020_06-46.zip'\n",
        "Test_ZipCSVFileName = 'amz_all_electronics/Data_Balanced_2000_Apr-03-2020_06-46/Test_2000_Apr-03-2020_06-46.zip'\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "df_train = pd.read_csv(Train_ZipCSVFileName)\n",
        "df_train.info()\n",
        "\n",
        "df_test = pd.read_csv(Test_ZipCSVFileName)\n",
        "df_test.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ0MFawpTLAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Get names of indexes for which column Age has value 30\n",
        "index_neutrals_train = df_train[ df_train['overall'] == 3 ].index\n",
        "index_neutrals_test = df_test[ df_test['overall'] == 3 ].index\n",
        " \n",
        "# Delete these row indexes from dataFrame\n",
        "df_train.drop(index_neutrals_train , inplace=True)\n",
        "df_test.drop(index_neutrals_test , inplace=True)\n",
        "\n",
        "df_train.loc[(df_train.overall == 1),'overall']= 1\n",
        "df_train.loc[(df_train.overall == 2),'overall']= 1\n",
        "df_train.loc[(df_train.overall == 4),'overall']= 5\n",
        "df_train.loc[(df_train.overall == 5),'overall']= 5\n",
        "\n",
        "df_test.loc[(df_test.overall == 1),'overall']= 1\n",
        "df_test.loc[(df_test.overall == 2),'overall']= 1\n",
        "df_test.loc[(df_test.overall == 4),'overall']= 5\n",
        "df_test.loc[(df_test.overall == 5),'overall']= 5\n",
        "\n",
        "df_train['reviewText_len'].describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cnj7F8PA_dG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_VOCAB_SIZE = 50000\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBSoDjOJBDjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "appdg2WIBGHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = Tokenizer(num_words= MAX_VOCAB_SIZE, filters='#$%&()*+<=>@[\\\\]^_`{|}~\\t\\n', lower=True)\n",
        "tokenizer.fit_on_texts(df_train['summary'] + ' '+ df_train['reviewText'])\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyTfW3wGBI6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tokenizer.texts_to_sequences(df_train['summary'] + ' DELIM '+ df_train['reviewText'])\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bwib_TlExtrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "# all parameters not specified are set to their defaults\n",
        "#logisticRegr = LogisticRegression(verbose=1, max_iter=10000)\n",
        "#logisticRegr.fit(X,df_train['overall'].values)\n",
        "\n",
        "model = SGDClassifier()\n",
        "model.fit(X,df_train['overall'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQW-aHKqQuRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test = tokenizer.texts_to_sequences(df_test['summary'] + ' DELIM '+ df_test['reviewText'])\n",
        "x_test = pad_sequences(x_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', x_test.shape)\n",
        "\n",
        "#predictions = logisticRegr.predict(x_test)\n",
        "#print(predictions)\n",
        "test_score = model.score(x_test,df_test['overall'].values) \n",
        "train_score = model.score(X,df_train['overall'].values) \n",
        "print(\"accuracy score\", score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kBwzaG6SOVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import metrics\n",
        "\n",
        "cm = metrics.confusion_matrix(df_test['overall'], predictions)\n",
        "\n",
        "# https://towardsdatascience.com/logistic-regression-using-python-sklearn-numpy-mnist-handwriting-recognition-matplotlib-a6b31e2b166a\n",
        "plt.figure(figsize=(9,9))\n",
        "sns.heatmap(cm, annot=True, fmt=\".1f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
        "plt.ylabel('Actual label');\n",
        "plt.xlabel('Predicted label');\n",
        "all_sample_title = 'Accuracy Score: {0}'.format(score)\n",
        "plt.title(all_sample_title, size = 15);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjERP5zJQkMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "x_test = tokenizer.texts_to_sequences(df_test['reviewText'].values)\n",
        "x_test = pad_sequences(x_test, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "#print('Shape of data tensor:', X_test.shape)\n",
        "\n",
        "Y_test = pd.get_dummies(df_test['overall']).values\n",
        "#print('Shape of label tensor:', Y_Test.shape)\n",
        "\n",
        "\n",
        "#logisticRegr.predict(x_test[0].reshape(1,-1))\n",
        "predictions = logisticRegr.predict(x_test)\n",
        "# Use score method to get accuracy of model\n",
        "score = logisticRegr.score(x_test, df_test['overall'])\n",
        "print(\"test accuracy\",score)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}